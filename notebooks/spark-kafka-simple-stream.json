{"paragraphs":[{"text":"%spark.dep\nz.load(\"org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.1\")\nz.load(\"org.apache.kafka:kafka-clients:0.11.0.1\")\n","user":"anonymous","dateUpdated":"2018-08-24T10:48:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@50fe47dc\n"}]},"apps":[],"jobName":"paragraph_1535064846878_-293590706","id":"20180823-225406_1441088736","dateCreated":"2018-08-23T22:54:06+0000","dateStarted":"2018-08-24T09:50:20+0000","dateFinished":"2018-08-24T09:51:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:61004","title":"Load the Dependencies to run this Program on Zeppelin NoteBook"},{"text":"\nimport org.apache.spark._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.sql.types.TimestampType\n","user":"anonymous","dateUpdated":"2018-08-24T10:49:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.sql.types.TimestampType\n"}]},"apps":[],"jobName":"paragraph_1535064861200_-662996757","id":"20180823-225421_63900274","dateCreated":"2018-08-23T22:54:21+0000","dateStarted":"2018-08-24T10:29:58+0000","dateFinished":"2018-08-24T10:31:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61005","title":"Import the Required Libraries"},{"text":" val spark: SparkSession = SparkSession.builder().appName(\"spark-kafka\").master(\"local[*]\").getOrCreate()","user":"anonymous","dateUpdated":"2018-08-24T10:49:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@43dc2817\n"}]},"apps":[],"jobName":"paragraph_1535065446218_-1485615519","id":"20180823-230406_1141333169","dateCreated":"2018-08-23T23:04:06+0000","dateStarted":"2018-08-24T10:31:58+0000","dateFinished":"2018-08-24T10:32:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61006","title":"Create the Spark Session Object"},{"text":"val mySchema = StructType(Array(\n StructField(\"id\", IntegerType),\n StructField(\"name\", StringType),\n StructField(\"year\", IntegerType),\n StructField(\"rating\", DoubleType),\n StructField(\"duration\", IntegerType)\n))","user":"anonymous","dateUpdated":"2018-08-24T10:50:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"mySchema: org.apache.spark.sql.types.StructType = StructType(StructField(id,IntegerType,true), StructField(name,StringType,true), StructField(year,IntegerType,true), StructField(rating,DoubleType,true), StructField(duration,IntegerType,true))\n"}]},"apps":[],"jobName":"paragraph_1535065542578_1986743712","id":"20180823-230542_385796558","dateCreated":"2018-08-23T23:05:42+0000","dateStarted":"2018-08-24T10:32:39+0000","dateFinished":"2018-08-24T10:32:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61007","title":"Define your schema - This is for Structured Streaming"},{"text":"val streamingDataFrame = spark.readStream.schema(mySchema).csv(\"/tmp/moviedata.csv\")","user":"anonymous","dateUpdated":"2018-08-24T10:52:26+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"streamingDataFrame: org.apache.spark.sql.DataFrame = [id: int, name: string ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1535065668578_1492097328","id":"20180823-230748_20492506","dateCreated":"2018-08-23T23:07:48+0000","dateStarted":"2018-08-24T10:33:14+0000","dateFinished":"2018-08-24T10:33:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61008","title":"Create a DataFrame which reads your Data (moviedata.csv). This Data resides in your /tmp directory of your pod"},{"text":"import spark.implicits._\n(streamingDataFrame.selectExpr(\"CAST(id AS STRING) AS key\", \"to_json(struct(*)) AS value\").\n  writeStream\n  .format(\"console\")\n  .option(\"topic\", \"my-topic\")\n  .option(\"kafka.bootstrap.servers\", \"172.30.218.203:9092\")\n  .option(\"checkpointLocation\", \"tmp/moviedata.csv\")\n  .start())","user":"anonymous","dateUpdated":"2018-08-24T10:56:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nres8: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@5714d9b\n"}]},"apps":[],"jobName":"paragraph_1535065970358_551175421","id":"20180823-231250_717054583","dateCreated":"2018-08-23T23:12:50+0000","dateStarted":"2018-08-24T10:34:00+0000","dateFinished":"2018-08-24T10:34:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61009","title":"Publish to Kafka - Push to Kafka (172.30.218.203:9092) is your clusterip address in this Pod, Topic name - my-topic"},{"text":"import spark.implicits._\n","user":"anonymous","dateUpdated":"2018-08-24T10:55:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\n"}]},"apps":[],"jobName":"paragraph_1535066117098_-1975330492","id":"20180823-231517_138945865","dateCreated":"2018-08-23T23:15:17+0000","dateStarted":"2018-08-24T10:35:01+0000","dateFinished":"2018-08-24T10:35:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61010","title":"Import Statement"},{"text":"val df = (spark\n  .readStream\n  .format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", \"172.30.218.203:9092\")\n  .option(\"subscribe\", \"my-topic\")\n  .load())\n   \n","user":"anonymous","dateUpdated":"2018-08-24T10:57:08+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1535066207462_-1576258650","id":"20180823-231647_916093381","dateCreated":"2018-08-23T23:16:47+0000","dateStarted":"2018-08-24T10:35:23+0000","dateFinished":"2018-08-24T10:35:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61011","title":"Subscribe from the Same Topic (my-topic) - Read from the same Topic "},{"text":"import java.sql.Timestamp\n\nval df1 = (df.selectExpr(\"CAST(value AS STRING)\", \"CAST(timestamp AS TIMESTAMP)\").as[(String, Timestamp)]\n  .select(from_json($\"value\", mySchema).as(\"data\"), $\"timestamp\")\n  .select(\"data.*\", \"timestamp\"))\n","user":"anonymous","dateUpdated":"2018-08-24T10:58:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.sql.Timestamp\ndf1: org.apache.spark.sql.DataFrame = [id: int, name: string ... 4 more fields]\n"}]},"apps":[],"jobName":"paragraph_1535066267464_-1686233757","id":"20180823-231747_307213098","dateCreated":"2018-08-23T23:17:47+0000","dateStarted":"2018-08-24T10:37:29+0000","dateFinished":"2018-08-24T10:37:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61012","title":"Convert this stream according to the structure defined in (mySchema) along with the time stamp "},{"text":"(df1.writeStream\n    .format(\"console\")\n    .option(\"truncate\",\"false\")\n    .start()\n    .awaitTermination())\n","user":"anonymous","dateUpdated":"2018-08-24T10:58:54+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:437)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:307)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1535066334364_-1823648433","id":"20180823-231854_1567063145","dateCreated":"2018-08-23T23:18:54+0000","dateStarted":"2018-08-24T10:38:47+0000","dateFinished":"2018-08-24T10:38:59+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:61013","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:437)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:307)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","title":"Print the output to console, Facing memory issue here (as it is writing the huge file), Will increase the memory in zeppelin upto 1G (upto 10G are allowable limits)and fix this. "},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1535103853308_-154326648","id":"20180824-094413_296641697","dateCreated":"2018-08-24T09:44:13+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:61014"}],"name":"spark-kafka-simple-stream","id":"2DRN5N71P","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}